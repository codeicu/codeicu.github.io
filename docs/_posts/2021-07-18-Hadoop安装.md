---
layout: post
title: "Hadoop安装"
date: 2021-07-18T08:29:45+08:00
draft: false
tags: 
categories:
author: Zink
---
# 安装
```
cd /home/zink
wget https://mirrors.tuna.tsinghua.edu.cn/apache/hadoop/common/stable/hadoop-3.3.1.tar.gz
sudo tar -zxf ./hadoop-3.3.1.tar.gz -C /usr/local
sudo useradd -m hadoop
sudo passwd hadoop
sudo usermod -g root hadoop

cd /usr/local
sudo mv ./hadoop-3.3.1 ./hadoop #重命名
sudo chown -R hadoop ./hadoop # 修改文件权限



wget https://mirrors.tuna.tsinghua.edu.cn/AdoptOpenJDK/11/jdk/x64/linux/OpenJDK11U-jdk_x64_linux_hotspot_11.0.11_9.tar.gz
tar -xvf OpenJDK11U-jdk_x64_linux_hotspot_11.0.11_9.tar.gz -C /usr/local/Java

配置环境变量（vim ~/.bashrc）
#HADOOP
export HADOOP_HOME=/usr/local/hadoop
export PATH=$PATH:/usr/local/hadoop/bin
#JAVA
export JAVA_HOME=/usr/local/Java/jdk11/
export JRE_HOME=$JAVA_HOME/jre
export PATH=$JAVA_HOME/bin:$JRE_HOME/bin:$PATH
export CLASSPATH=$JAVA_HOME/lib:$JRE_HOME/lib:.

cd /usr/local/hadoop
hadoop jar ./share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.1.jar 
```
# Hadoop单机部署

```
默认为非分布式模式，无须进行其他配置即可运行。附带了很多例子，可以直接查看所有例子：
cd /usr/local/hadoop
hadoop jar ./share/hadoop/mapreduce/hadoop-mapreduce-examples-3.3.1.jar 

会显示grep，join，wordcount等例子

这里选择grep例子，流程为先建一个input文件夹，并复制一些文件到该文件；然后运行grep程序，
将input文件夹的所有文件作为grep的输入，让grep程序从所有文件中筛选出符合正则表达式的单词，
并输出结果到output

mkdir input
cp ./etc/hadoop/*.xml ./input
hadoop jar ./share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.1.jar grep ./input ./output 'dfs[a-z.]+'

这里需要注意的是，hadoop默认要求输出output不存在，若存在则会报错

查看运行结果cat ./output/*
```

# Hadoop伪分布式部署
Hadoop 的配置文件位于 /usr/local/hadoop/etc/hadoop/中，伪分布式需要修改2个配置文件 core-site.xml和 hdfs-site.xml
配置文件是 xml格式，每个配置以声明 property的 name 和 value的方式来实现
Hadoop在启动时会读取配置文件，根据配置文件来决定运行在什么模式下

```
vim core-site.xml

修改为
<configuration>
    <property>
     <name>hadoop.tmp.dir</name>
     <value>file:/usr/local/hadoop/tmp</value>
     <description>Abase for other temporary directories.</description>
    </property>
 <property>
     <name>fs.defaultFS</name>
     <value>hdfs://localhost:9000</value>
 </property>
</configuration>

vim hdfs-site.xml
修改为

<configuration>
    <property>
        <name>dfs.replication</name>
        <value>1</value>
    </property>
    <property>
        <name>dfs.namenode.name.dir</name>
        <value>file:/usr/local/hadoop/tmp/dfs/name</value>
    </property>
    <property>
       <name>dfs.datanode.data.dir</name>
       <value>file:/usr/local/hadoop/tmp/dfs/data</value>
    </property>
</configuration>

dfs.replication表示副本的数量，伪分布式要设置为1

dfs.namenode.name.dir表示名称节点的元数据保存目录

dfs.datanode.data.dir表示数据节点的数据保存目录


cd /usr/local/hadoop/
./bin/hdfs namenode -format

启动Hadoop
cd /usr/local/hadoop
./sbin/start-dfs.sh

关闭Hadoop
cd /usr/local/hadoop
./sbin/stop-dfs.sh

```
